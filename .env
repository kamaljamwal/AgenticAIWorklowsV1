# LLM Provider Configuration - Using GROQ (free tier)
LLM_PROVIDER=groq
GROQ_API_KEY=
GROQ_MODEL=llama3-8b-8192

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8001
LOG_LEVEL=INFO

# Content Processing Configuration
CONTENT_CHUNK_SIZE=1000
CONTENT_OVERLAP_SIZE=200
CONTENT_MAX_FILE_SIZE=10485760
ENABLE_CONTENT_INDEXING=true
INDEX_UPDATE_INTERVAL=3600

# FileSystem Configuration (for testing)
FILESYSTEM_PATHS=c:\Users\kamal\CascadeProjects\AgenticAIWorklows
FILESYSTEM_EXTENSIONS=.txt,.md,.py,.js,.json,.csv,.log,.pdf,.docx
FILESYSTEM_EXCLUDE_DIRS=node_modules,__pycache__,.git,.venv,env

# Basic configurations for other agents (can be expanded later)
JIRA_SERVER=https://example.atlassian.net
JIRA_EMAIL=test@example.com
JIRA_API_TOKEN=placeholder

GITHUB_TOKEN=placeholder
GITHUB_REPOS=example/repo

AWS_ACCESS_KEY_ID=placeholder
AWS_SECRET_ACCESS_KEY=placeholder
AWS_REGION=us-east-1
S3_BUCKET_NAME=placeholder
