# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# AWS Bedrock Configuration (for LLM_PROVIDER=aws)
AWS_BEDROCK_REGION=us-east-1
AWS_BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# GROQ Configuration (for LLM_PROVIDER=groq)
# Get your API key from https://console.groq.com/keys
GROQ_API_KEY=
GROQ_MODEL=llama3-8b-8192  # Available: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768, gemma-7b-it

# Google Gemini Configuration (for LLM_PROVIDER=gemini)
# Get your API key from https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash  # Available: gemini-1.5-flash (free), gemini-1.5-pro (free tier)

# LLM Provider Configuration 
# Choose one: openai, aws, groq, gemini, ollama, huggingface, together, replicate, local_openai
LLM_PROVIDER=groq

# ===== OPEN SOURCE & FREE LLM OPTIONS =====

# Ollama Configuration (Local Models - FREE)
# Install Ollama from https://ollama.ai/ and run: ollama pull llama2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2  # Available: llama2, mistral, codellama, vicuna, etc.

# Hugging Face Transformers (Local Inference - FREE)
# Runs models locally on your machine
HUGGINGFACE_MODEL=microsoft/DialoGPT-medium  # or any compatible model
HUGGINGFACE_DEVICE=auto  # auto, cpu, cuda
HUGGINGFACE_CACHE_DIR=./hf_cache

# Together AI (Free Tier Available)
# Sign up at https://together.ai/ for free credits
TOGETHER_API_KEY=your_together_api_key_here
TOGETHER_MODEL=togethercomputer/llama-2-7b-chat

# Replicate (Free Tier Available)
# Sign up at https://replicate.com/ for free credits
REPLICATE_API_TOKEN=your_replicate_token_here
REPLICATE_MODEL=meta/llama-2-7b-chat

# Local OpenAI-compatible Server (FREE)
# Works with LM Studio, text-generation-webui, FastChat, etc.
LOCAL_OPENAI_BASE_URL=http://localhost:1234/v1
LOCAL_OPENAI_MODEL=local-model
LOCAL_OPENAI_API_KEY=not-needed

# JIRA Configuration
JIRA_SERVER=https://your-company.atlassian.net
JIRA_EMAIL=your-email@company.com
JIRA_API_TOKEN=your_jira_api_token
JIRA_PROJECTS=PROJ1,PROJ2,PROJ3

# GitHub Configuration
GITHUB_TOKEN=your_github_personal_access_token
GITHUB_REPOS=owner/repo1,owner/repo2,owner/repo3
GITHUB_ORGANIZATIONS=your-org1,your-org2

# AWS S3 Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your-s3-bucket-name
S3_CONTENT_PREFIXES=documents/,reports/,data/

# FileSystem Configuration
FILESYSTEM_PATHS=C:/Projects,C:/Documents,C:/Data
FILESYSTEM_EXTENSIONS=.txt,.md,.py,.js,.json,.csv,.log,.pdf,.docx
FILESYSTEM_EXCLUDE_DIRS=node_modules,__pycache__,.git,venv,env

# Video Sources Configuration
VIDEO_SOURCES=youtube,local
VIDEO_YOUTUBE_CHANNELS=UC_channel_id1,UC_channel_id2
VIDEO_YOUTUBE_PLAYLISTS=PLplaylist_id1,PLplaylist_id2
VIDEO_LOCAL_PATHS=C:/Videos/Training,C:/Videos/Tutorials
VIDEO_SUPPORTED_FORMATS=.mp4,.avi,.mkv,.mov,.wmv

# URL Sources Configuration
URL_SOURCES=https://medium.com,https://docs.company.com,https://wiki.company.com
URL_CRAWL_DEPTH=2
URL_ALLOWED_DOMAINS=example.com,company.com

# API Sources Configuration
API_ENDPOINTS=https://api.example.com/v1,https://internal-api.company.com/api
API_HEADERS_ENDPOINT1=Authorization:Bearer token1,Content-Type:application/json
API_HEADERS_ENDPOINT2=X-API-Key:your_api_key,Content-Type:application/json

# Content Processing Configuration
CONTENT_CHUNK_SIZE=1000
CONTENT_OVERLAP_SIZE=200
CONTENT_MAX_FILE_SIZE=10485760
ENABLE_CONTENT_INDEXING=true
INDEX_UPDATE_INTERVAL=3600

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
LOG_LEVEL=INFO
